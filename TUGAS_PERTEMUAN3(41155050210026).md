NAMA		: PUTRI LUTFIANA WEEBEE PRASETYO

NPM		: 41155050210026

TUGAS PERTEMUAN 3


1.	
PENGENALAN KOMPONEN DECISION TREE: ROOT, NODE, LEAF
Decision tree adalah salah satu metode machine learning yang digunakan untuk membuat keputusan berdasarkan serangkaian aturan berbasis data. Pohon keputusan ini terbentuk dari beberapa komponen dasar, yaitu root, node, dan leaf.
Root adalah node pertama dari sebuah pohon keputusan. Ini merupakan titik awal di mana seluruh data mulai dibagi berdasarkan fitur yang paling penting. Root memegang keseluruhan dataset dan kemudian membagi dataset tersebut ke cabang-cabang berdasarkan kriteria tertentu. Internal node adalah Node yang memiliki cabang ke node lain dan merupakan titik di mana keputusan dibuat. Leaf adalah node terakhir dari pohon keputusan dan tidak memiliki cabang lebih lanjut. Di sini, keputusan akhir dibuat, yang bisa berupa klasifikasi atau hasil prediksi. Leaf merepresentasikan hasil atau output dari pohon berdasarkan input yang telah diproses.


PENGENALAN GINI IMPURITY
Gini Impurity adalah salah satu metode yang digunakan dalam pohon keputusan (decision tree) untuk mengukur kualitas split atau pembagian data di setiap node. Tujuannya adalah untuk menentukan seberapa "bersih" pembagian data di node tertentu dalam pohon keputusan, terutama dalam masalah klasifikasi.


PENGENALAN INFORMATION GAIN
Information Gain adalah ukuran yang digunakan dalam pohon keputusan (decision tree) untuk memilih fitur yang akan digunakan untuk membagi data pada setiap node. Konsep ini didasarkan pada teori informasi dan digunakan untuk menentukan seberapa baik suatu fitur memisahkan data ke dalam kelas yang berbeda.


MEMBANGUN DECISION TREE
Pembangunan pohon keputusan (decision tree) melibatkan beberapa langkah untuk memecah dataset menjadi bagian-bagian yang lebih kecil hingga mencapai kondisi yang optimal, di mana setiap node dalam pohon memberikan klasifikasi atau keputusan yang akurat.
Proses pembangunan decision tree melibatkan pemilihan fitur secara iteratif untuk membagi data secara optimal, hingga mencapai titik di mana pembagian lebih lanjut tidak memberikan informasi tambahan. Proses ini dapat ditingkatkan dengan teknik pruning untuk menghindari overfitting, sehingga pohon dapat memprediksi data baru secara akurat.


PERSIAPAN DATASET: IRIS DATASET
 ![image](https://github.com/user-attachments/assets/fea7f1cf-9c21-4494-b5fb-e505f23d4b4d)


TRAINING MODEL DECISION TREE CLASSIFIER
 ![image](https://github.com/user-attachments/assets/a04d5ebe-b964-4ad5-99a4-dd91b4c590ee)



VISUALISASI MODEL DECISION TREE
 ![image](https://github.com/user-attachments/assets/44f2e835-e6a6-49f5-885b-3d79e8ae04cf)



EVALUASI MODEL DECISION TREE
 ![image](https://github.com/user-attachments/assets/7c65221b-ffc5-48fd-a4cc-c2f61fb3037a)


2.	
PROSES TRAINING MODEL MACHINE LEARNING SECARA UMUM

Proses training model machine learning melibatkan beberapa langkah penting yang dilakukan secara sistematis untuk membangun model yang dapat memprediksi atau mengklasifikasikan data baru dengan akurat. Keberhasilan model tergantung pada kualitas data, pemilihan algoritma yang tepat, dan strategi evaluasi serta tuning yang cermat. Monitoring setelah deployment juga sangat penting untuk memastikan model tetap akurat dan relevan seiring waktu.


PENGENALAN ENSEMBLE LEARNING
Ensemble learning adalah teknik yang kuat dalam machine learning yang menggabungkan beberapa model untuk meningkatkan kinerja prediksi. Dengan menggunakan metode seperti bagging, boosting, dan stacking, ensemble learning dapat mengatasi keterbatasan dari model individu dan menghasilkan model yang lebih akurat, stabil, dan generalis. Meskipun lebih kompleks, pendekatan ini sangat efektif untuk menangani berbagai jenis masalah, terutama dalam skenario di mana akurasi prediksi menjadi prioritas utama.


PENGENALAN BOOSTRAP AGGREGATING | BAGGING
Bagging adalah teknik ensemble learning yang efektif dalam meningkatkan akurasi dan mengurangi overfitting, terutama pada model dengan varians tinggi seperti decision trees. Dengan melatih beberapa model pada subset yang berbeda dari data, Bagging menciptakan model yang lebih stabil, konsisten, dan akurat. Contoh implementasi yang populer dari Bagging adalah algoritma Random Forest, yang sering digunakan dalam berbagai masalah machine learning karena kemampuannya yang baik dalam menangani data yang kompleks dan bervariasi.


PENGENALAN RANDOM FOREST | HUTAN ACAK
Random Forest adalah algoritma ensemble learning yang sangat kuat dan fleksibel, yang digunakan untuk masalah klasifikasi dan regresi. Dengan menggabungkan beberapa decision tree yang dibangun dari subset acak data dan fitur, Random Forest mampu mengurangi overfitting, mengurangi varians, dan meningkatkan akurasi prediksi. Algoritma ini sangat cocok untuk data yang kompleks, dan menjadi salah satu algoritma yang paling sering digunakan dalam berbagai aplikasi machine learning.


PERSIAPAN DATASET | IRIS FLOWER DATASET
 ![image](https://github.com/user-attachments/assets/b37489ff-047c-4e5f-b569-10ca7ee68fba)



IMPLEMENTASI RANDOM FOREST CLASSIFIER DENGAN SCIKIT LEARN
 ![image](https://github.com/user-attachments/assets/e621a821-59fd-4d3f-9043-a04dbb030e58)



EVALUASI MODEL DENGAN CLASSIFICATION REPORT
 ![image](https://github.com/user-attachments/assets/aa3efd3e-3fdb-4237-bc71-59ab2e22731e)


